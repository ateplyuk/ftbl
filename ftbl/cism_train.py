{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom PIL import Image\nimport os\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.optim as optim\nfrom torchvision import transforms, utils, datasets\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\nEPOCHS = 5\nLR = 0.0001\nIM_SIZE = 300\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nTRAIN_DIR = '../input/football/GrayScaleTrain/'\n\nimage_transforms = transforms.Compose([\n        transforms.Resize((IM_SIZE, IM_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5, 0.5, 0.5],\n                             [0.5, 0.5, 0.5])\n    ])\n\nimg_dataset = datasets.ImageFolder(root = TRAIN_DIR, transform = image_transforms)\n\nidx2class = {v: k for k, v in img_dataset.class_to_idx.items()}\nNUM_CL = len(idx2class)\n\nimg_dataset_size = len(img_dataset)\nimg_dataset_indices = list(range(img_dataset_size))\n\nnp.random.shuffle(img_dataset_indices)\n\ntest_split_index = int(np.floor(0.3 * img_dataset_size))\ntrain_idx, test_idx = img_dataset_indices[test_split_index:], img_dataset_indices[:test_split_index]\n\nval_split_index = int(np.floor(0.3 * len(test_idx)))\nval_idx, test_idx = test_idx[val_split_index:], test_idx[:val_split_index]\n\nprint(len(train_idx), len(val_idx), len(test_idx))\n\ntrain_sampler = SubsetRandomSampler(train_idx)\nval_sampler = SubsetRandomSampler(val_idx)\n\ntrain_loader = DataLoader(dataset=img_dataset, shuffle=False, batch_size=8, sampler=train_sampler)\nval_loader = DataLoader(dataset=img_dataset, shuffle=False, batch_size=1, sampler=val_sampler)\n\nsingle_batch = next(iter(train_loader))\nsingle_batch[0].shape\n\nclass FblClassifier(nn.Module):\n    def __init__(self):\n        super(FblClassifier, self).__init__()\n        self.block1 = self.conv_block(c_in=3, c_out=256, dropout=0.1, kernel_size=5, stride=1, padding=2)\n        self.block2 = self.conv_block(c_in=256, c_out=128, dropout=0.1, kernel_size=3, stride=1, padding=1)\n        self.block3 = self.conv_block(c_in=128, c_out=64, dropout=0.1, kernel_size=3, stride=1, padding=1)\n        self.lastcnn = nn.Conv2d(in_channels=64, out_channels=NUM_CL, kernel_size=75, stride=1, padding=0)\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n    def forward(self, x):\n        x = self.block1(x)\n        x = self.maxpool(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.maxpool(x)\n        x = self.lastcnn(x)\n        return x\n    def conv_block(self, c_in, c_out, dropout, **kwargs):\n        seq_block = nn.Sequential(\n            nn.Conv2d(in_channels=c_in, out_channels=c_out, **kwargs),\n            nn.BatchNorm2d(num_features=c_out),\n            nn.ReLU(),\n            nn.Dropout2d(p=dropout)\n        )\n        return seq_block\n    \nmodel = FblClassifier()\nmodel.to(DEVICE)\nprint(model)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LR)\n\ndef multi_acc(y_pred, y_test):\n    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n    correct_pred = (y_pred_tags == y_test).float()\n    acc = correct_pred.sum() / len(correct_pred)\n    acc = torch.round(acc * 100)\n    return acc\n\naccuracy_stats = {\n    'train': [],\n    \"val\": []\n}\nloss_stats = {\n    'train': [],\n    \"val\": []\n}\n\nprint(\"Begin training.\")\nfor e in tqdm(range(1, EPOCHS)):\n    # TRAINING\n    train_epoch_loss = 0\n    train_epoch_acc = 0\n    model.train()\n    for X_train_batch, y_train_batch in train_loader:\n        X_train_batch, y_train_batch = X_train_batch.to(DEVICE), y_train_batch.to(DEVICE)\n        optimizer.zero_grad()\n        y_train_pred = model(X_train_batch).squeeze()\n        train_loss = criterion(y_train_pred, y_train_batch)\n        train_acc = multi_acc(y_train_pred, y_train_batch)\n        train_loss.backward()\n        optimizer.step()\n        train_epoch_loss += train_loss.item()\n        train_epoch_acc += train_acc.item()\n    # VALIDATION\n    with torch.no_grad():\n        model.eval()\n        val_epoch_loss = 0\n        val_epoch_acc = 0\n        for X_val_batch, y_val_batch in val_loader:\n            X_val_batch, y_val_batch = X_val_batch.to(DEVICE), y_val_batch.to(DEVICE)\n            y_val_pred = model(X_val_batch).squeeze()\n            y_val_pred = torch.unsqueeze(y_val_pred, 0)\n            val_loss = criterion(y_val_pred, y_val_batch)\n            val_acc = multi_acc(y_val_pred, y_val_batch)\n            val_epoch_loss += train_loss.item()\n            val_epoch_acc += train_acc.item()\n    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n    print(f'Epoch {e+0:02}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')\n    \n    \n    torch.save(model.state_dict(), './fotmodel.pt')\n   \n\n# Inference\ntest_sampler = SubsetRandomSampler(test_idx)\ntest_loader = DataLoader(dataset=img_dataset, shuffle=False, batch_size=1, sampler=test_sampler)\n\ny_pred_list = []\ny_true_list = []\nwith torch.no_grad():\n    for x_batch, y_batch in tqdm(test_loader):\n        x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n        y_test_pred = model(x_batch)\n        _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n        y_pred_list.append(y_pred_tag.cpu().numpy())\n        y_true_list.append(y_batch.cpu().numpy())\n        \ny_pred_list = [i[0][0][0] for i in y_pred_list]\ny_true_list = [i[0] for i in y_true_list]\n\nprint(classification_report(y_true_list, y_pred_list))\n\nprint(confusion_matrix(y_true_list, y_pred_list))","metadata":{"_uuid":"df745f58-cc92-45df-9c84-ce298d8605b8","_cell_guid":"0914b037-45dc-4d3d-afc4-2b19cda40b5f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-05-11T05:17:01.338385Z","iopub.execute_input":"2022-05-11T05:17:01.338675Z","iopub.status.idle":"2022-05-11T05:32:31.274365Z","shell.execute_reply.started":"2022-05-11T05:17:01.338644Z","shell.execute_reply":"2022-05-11T05:32:31.273407Z"},"trusted":true},"execution_count":4,"outputs":[]}]}